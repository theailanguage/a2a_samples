# version_4p01_with_vision_agent

ðŸŒŸ **Purpose**  
This repository builds on version 4 of our multi-agent A2A + MCP architecture by adding a **Gemini-based VisionAgent** that can analyze images via file path or URL. Youâ€™ll see how a lightweight front-end client, a central Host OrchestratorAgent, and specialized agents (like VisionAgent, TellTimeAgent, and GreetingAgent) collaborate over Googleâ€™s Agent-to-Agent (A2A) protocol and Anthropicâ€™s Model Context Protocol (MCP).

---

## ðŸš€ Features

- **Gemini Vision Agent** â€“ Accepts text+image input and answers image-based questions using `gemini-2.0-flash`
- **A2A Protocol** â€“ Agents discover and call each other over JSON-RPC
- **MCP Integration** â€“ Automatically discovers and invokes tools hosted via MCP
- **Orchestrator Agent** â€“ A central Gemini-powered router that connects everything
- **Modular & Extensible** â€“ Add agents or tools by updating JSON config

---

## ðŸ“¦ Project Structure

```bash
version_4p01_with_vision_agent/
â”œâ”€â”€ .env                             # Contains GOOGLE_API_KEY (gitignored)
â”œâ”€â”€ pyproject.toml                   # Project metadata & dependencies
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ utilities/
â”‚   â”œâ”€â”€ a2a/
â”‚   â”‚   â”œâ”€â”€ agent_discovery.py       # Loads agent_registry.json
â”‚   â”‚   â”œâ”€â”€ agent_connect.py         # Calls agents using JSON-RPC
â”‚   â”‚   â””â”€â”€ agent_registry.json      # Defines A2A agents (VisionAgent, etc.)
â”‚   â””â”€â”€ mcp/
â”‚       â”œâ”€â”€ mcp_discovery.py         # Loads MCP servers
â”‚       â”œâ”€â”€ mcp_connect.py           # Loads & calls tools via MCP
â”‚       â””â”€â”€ mcp_config.json          # Defines MCP servers & tools
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ tell_time_agent/             # Returns the current time
â”‚   â”œâ”€â”€ greeting_agent/              # Returns a poetic greeting based on time of day
â”‚   â”œâ”€â”€ vision_agent/                # NEW: Accepts image + query
â”‚   â”‚   â”œâ”€â”€ __main__.py              # Starts the vision agent
â”‚   â”‚   â”œâ”€â”€ agent.py                 # Loads Gemini + handles image input
â”‚   â”‚   â””â”€â”€ task_manager.py          # Routes incoming tasks to the agent
â”‚   â””â”€â”€ host_agent/                  # Central orchestrator
â”‚       â”œâ”€â”€ entry.py
â”‚       â”œâ”€â”€ orchestrator.py
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ server.py                    # A2A JSON-RPC server
â”‚   â””â”€â”€ task_manager.py              # In-memory task tracking
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ a2a_client.py                # Makes JSON-RPC task requests
â”œâ”€â”€ app/
â”‚   â””â”€â”€ cmd/
â”‚       â””â”€â”€ cmd.py                   # CLI to interact with host agent
â””â”€â”€ models/
    â”œâ”€â”€ agent.py
    â”œâ”€â”€ json_rpc.py
    â”œâ”€â”€ request.py
    â””â”€â”€ task.py
````

---

## ðŸ› ï¸ Prerequisites

* Python 3.11+
* [uv](https://github.com/astral-sh/uv)
* Valid `GOOGLE_API_KEY` with Gemini access

---

## âš™ï¸ Setup & Install

```bash
# Clone the repo
cd version_4p01_with_vision_agent
uv venv
source .venv/bin/activate
uv sync --all-groups

# Add your Gemini API Key
echo "GOOGLE_API_KEY=your_key_here" > .env
```

---

## ðŸŽ¥ Running the Demo

### 1. Start your agents

```bash
# VisionAgent
uv run python3 -m agents.vision_agent --host localhost --port 10003

# TellTimeAgent
uv run python3 -m agents.tell_time_agent --host localhost --port 10002

# GreetingAgent
uv run python3 -m agents.greeting_agent --host localhost --port 10001
```

### 2. Start the Orchestrator Host Agent

```bash
uv run python3 -m agents.host_agent.entry --host localhost --port 10000
```

### 3. Ask your Host Agent to describe an image!

```bash
uv run python3 -m app.cmd.cmd --agent http://localhost:10000
```

---

## ðŸ“… Architecture Overview

* **Client** â†’ Sends query + image to HostAgent
* **HostAgent** â†’ Detects VisionAgent via A2A registry, forwards task
* **VisionAgent** â†’ Uses Gemini to analyze the image & reply
* **Also includes** â†’ TellTimeAgent, GreetingAgent, and MCP Tool support

---

## ðŸ’¡ What This Teaches

* How to combine Gemini LLM with vision and external query routing
* How to architect multi-agent workflows using A2A
* How to wrap visual AI into callable services

---

## âœ¨ More Resources

* [The AI Language Course on Udemy](https://www.udemy.com/course/modelcontextprotocol/?referralCode=6FADE0F85C5DB97203C6)
* [Subscriber-only Code Access](https://theailanguage.com/onlySubscribers?id=a2a_samples&site=github)
* [Previous Video (Multi-agent orchestration with MCP)](https://www.youtube.com/watch?v=ALN7wSJ5pGI&list=PL6tW9BrhiPTCKTXXJAwigi7QDNpA7t4Ip)